<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ExpressBuddy Architecture - Complete System Flow</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            padding: 20px;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        header {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            text-align: center;
        }
        
        h1 {
            color: #667eea;
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .subtitle {
            color: #666;
            font-size: 1.1em;
        }
        
        .diagram-container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            overflow-x: auto;
        }
        
        .diagram-container h2 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 1.8em;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }
        
        .mermaid {
            display: flex;
            justify-content: center;
            background: #f9f9f9;
            padding: 20px;
            border-radius: 5px;
            min-height: 400px;
        }
        
        .description {
            margin-top: 20px;
            padding: 15px;
            background: #f0f7ff;
            border-left: 4px solid #667eea;
            border-radius: 4px;
            color: #333;
            line-height: 1.6;
        }
        
        footer {
            text-align: center;
            color: white;
            margin-top: 50px;
            padding: 20px;
        }
        
        .nav-buttons {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .nav-btn {
            padding: 10px 20px;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .nav-btn:hover {
            background: #764ba2;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        
        .nav-btn.active {
            background: #764ba2;
            border: 2px solid white;
        }
        
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8em;
            }
            
            .diagram-container {
                padding: 15px;
            }
            
            .mermaid {
                min-height: 300px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üéØ ExpressBuddy Architecture Diagrams</h1>
            <p class="subtitle">Complete System Flow & Components</p>
        </header>
        
        <div class="nav-buttons">
            <a href="#master" class="nav-btn active">Master Architecture</a>
            <a href="#pico" class="nav-btn">Pico Complexity</a>
            <a href="#flow" class="nav-btn">System Flow</a>
            <a href="#journey" class="nav-btn">User Journey</a>
            <a href="#memory" class="nav-btn">Memory System</a>
            <a href="#avatar" class="nav-btn">Avatar States</a>
            <a href="#tools" class="nav-btn">Tool Calling</a>
            <a href="#audio" class="nav-btn">Audio Pipeline</a>
        </div>
        
        <div id="master" class="diagram-container">
            <h2>üéØ MASTER ARCHITECTURE - Complete System Blueprint</h2>
            <div class="mermaid">
graph TB
    subgraph INPUT["üé§ INPUT LAYER"]
        Mic["Microphone<br/>16kHz PCM16"]
        VAD["Voice Activity<br/>Detection"]
    end
    
    subgraph STREAMING["üì° REAL-TIME STREAMING"]
        WebRTC["WebRTC Audio<br/>Stream"]
        Gemini["ü§ñ Gemini Live API<br/>(Multimodal)"]
        EventHandler["Event Handler<br/>setup|media|content|toolcall"]
    end
    
    subgraph PROCESSING["‚öôÔ∏è INTELLIGENT PROCESSING"]
        AIDecision["AI Decision Engine<br/>- Tool usage?<br/>- Response generation<br/>- Intent understanding"]
        ToolExecution["Tool Call Executor<br/>- Memory functions<br/>- Non-blocking async<br/>- Error handling"]
        BufferingSystem["Smart Buffering<br/>- Audio chunks<br/>- Text chunks<br/>- State sync"]
    end
    
    subgraph MEMORY["üíæ PERSISTENT MEMORY LAYER"]
        LocalStorage["localStorage<br/>Key-Value Store"]
        MemoryTools["Memory Tools<br/>- write_to_memory<br/>- get_memories_by_keys"]
        SessionState["Session State<br/>Memory Loaded"]
    end
    
    subgraph OUTPUT["üì§ OUTPUT SYNTHESIS"]
        AudioBuffer["Audio Buffer<br/>Combine Chunks"]
        TextAccumulator["Text Accumulator<br/>Subtitle Display"]
        StateManager["State Machine<br/>IDLE‚ÜíBUFF‚ÜíTALK‚ÜíIDLE"]
    end
    
    subgraph RENDERING["üé≠ AVATAR RENDERING"]
        VideoPlayer["MP4 Video Player<br/>Talking Animation"]
        ChromaKeyRemoval["Chroma Key<br/>Green Screen Removal"]
        AvatarDisplay["Final Avatar<br/>Rendered Output"]
    end
    
    subgraph PERSISTENCE["üíæ DATA PERSISTENCE"]
        Transcripts["Transcripts<br/>User & AI"]
        ConvDatabase["Conversation DB<br/>Supabase"]
        Analytics["Analytics<br/>Interaction Data"]
    end
    
    subgraph SPEAKER["üîä AUDIO OUTPUT"]
        AudioPlayback["Audio Playback<br/>PCM16 16kHz"]
        Speakers["Speaker Output<br/>User Hears Response"]
    end
    
    Mic -->|Continuous| VAD
    VAD -->|Detected| WebRTC
    WebRTC -->|Stream| Gemini
    
    Gemini -->|Events| EventHandler
    EventHandler -->|Content| AIDecision
    EventHandler -->|Media| BufferingSystem
    
    AIDecision -->|Decision| ToolDecision{Use Tools?}
    ToolDecision -->|YES| ToolExecution
    ToolDecision -->|NO| Continue["Continue Stream"]
    
    ToolExecution -->|Async Exec| MemoryTools
    MemoryTools -->|Store| LocalStorage
    MemoryTools -->|Response| AIDecision
    
    SessionState -->|Load on Init| AIDecision
    
    EventHandler -->|Audio Data| BufferingSystem
    EventHandler -->|Text Data| TextAccumulator
    
    BufferingSystem -->|turncomplete| AudioBuffer
    AudioBuffer -->|Process| StateManager
    StateManager -->|TALKING| VideoPlayer
    
    TextAccumulator -->|Subtitles| AvatarDisplay
    VideoPlayer -->|Video| ChromaKeyRemoval
    ChromaKeyRemoval -->|Clean| AvatarDisplay
    
    AudioBuffer -->|PCM16| AudioPlayback
    AudioPlayback -->|Sound| Speakers
    
    TextAccumulator -->|Capture| Transcripts
    Speakers -->|When Done| Transcripts
    
    Transcripts -->|Store| ConvDatabase
    Transcripts -->|Track| Analytics
    
    Speakers -->|Audio End| StateManager
    StateManager -->|Transition| Continue
            </div>
            <div class="description">
                <strong>üéØ MASTER ARCHITECTURE:</strong> This is the complete system blueprint showing all major components working together:
                <br><strong>Key Layers:</strong>
                <br>‚Ä¢ <strong>INPUT:</strong> Audio capture with VAD (Voice Activity Detection) for interruption handling
                <br>‚Ä¢ <strong>STREAMING:</strong> Real-time bidirectional communication with Gemini via WebRTC
                <br>‚Ä¢ <strong>PROCESSING:</strong> AI decision engine with tool execution and intelligent buffering
                <br>‚Ä¢ <strong>MEMORY:</strong> Persistent non-blocking memory system using localStorage and memory tools
                <br>‚Ä¢ <strong>OUTPUT:</strong> Smart buffering and state management for smooth transitions
                <br>‚Ä¢ <strong>RENDERING:</strong> Avatar animation with chroma key processing
                <br>‚Ä¢ <strong>PERSISTENCE:</strong> Comprehensive transcript and analytics storage
                <br>‚Ä¢ <strong>SPEAKER:</strong> Real-time audio output to user
            </div>
        </div>
        
        <div class="diagram-container">
            <h2>üèóÔ∏è Component Architecture</h2>
            <div class="mermaid">
graph TB
    subgraph React["React Components"]
        Main["MainInterfaceWithAvatar"]
        Avatar["VideoExpressBuddyAvatar"]
        Captions["Captions"]
        Control["ControlTray"]
        Nudge["NudgeIndicator"]
    end
    
    subgraph Context["Context & Hooks"]
        LiveAPICtx["LiveAPIContext"]
        Hook["use-live-api.ts"]
        BufferHook["useResponseBuffer"]
        HintHook["useHintSystem"]
    end
    
    subgraph Services["Services"]
        TranscriptSvc["TranscriptService"]
        GenaiClient["GenAILiveClient"]
    end
    
    subgraph Storage["Storage"]
        LocalStore["localStorage"]
        Supabase["Supabase DB"]
    end
    
    subgraph External["External APIs"]
        Gemini["ü§ñ Gemini<br/>Live API"]
        WebRTC["üåê WebRTC<br/>Audio"]
    end
    
    Main -->|Uses| LiveAPICtx
    Avatar -->|Uses| Main
    Captions -->|Uses| Main
    Control -->|Uses| Main
    Nudge -->|Uses| Main
    
    LiveAPICtx -->|Provides| Hook
    Hook -->|Manages| GenaiClient
    Hook -->|Uses| BufferHook
    Hook -->|Uses| HintHook
    
    Main -->|Uses| TranscriptSvc
    TranscriptSvc -->|Logs to| Supabase
    TranscriptSvc -->|Records| LocalStore
    
    HintHook -->|Sends to| GenaiClient
    BufferHook -->|Buffers| Main
    
    GenaiClient -->|Communicates| Gemini
    GenaiClient -->|Streams| WebRTC
    
    Hook -->|Stores memory| LocalStore
    Main -->|Tool calls| LocalStore
            </div>
            <div class="description">
                <strong>Components:</strong> Shows how React components, hooks, services, and external APIs interact. All components flow through the LiveAPIContext for state management and communication with the Gemini Live API.
            </div>
        </div>
        
        <div id="pico" class="diagram-container">
            <h2>‚ö° PICO COMPLEXITY - Technical Excellence & Innovation</h2>
            <div class="mermaid">
graph TB
    subgraph COMPLEXITY["üî¥ Core Complexity Points"]
        RealTime["Real-Time Bidirectional<br/>Audio Streaming<br/>‚Ä¢ 16kHz PCM16 chunks<br/>‚Ä¢ Sub-200ms latency<br/>‚Ä¢ WebRTC protocol"]
        
        StateMachine["üé≠ Smart State Machine<br/>‚Ä¢ IDLE ‚Üí BUFFERING ‚Üí TALKING ‚Üí IDLE<br/>‚Ä¢ Seamless transitions<br/>‚Ä¢ No gaps or overlaps"]
        
        EventDriven["üì° Async Event Architecture<br/>‚Ä¢ setup|media|content|toolcall<br/>‚Ä¢ Non-blocking async handlers<br/>‚Ä¢ Proper error recovery"]
        
        MemoryMagic["üíæ Intelligent Memory<br/>‚Ä¢ NON_BLOCKING async operations<br/>‚Ä¢ localStorage persistence<br/>‚Ä¢ Session context loading<br/>‚Ä¢ Memory-aware AI responses"]
        
        ToolCalling["üîß AI Tool Execution<br/>‚Ä¢ Tool declarations to Gemini<br/>‚Ä¢ Async tool call handling<br/>‚Ä¢ Response injection back<br/>‚Ä¢ Streaming continuation"]
        
        BufferSync["üì¶ Chunk Synchronization<br/>‚Ä¢ Audio chunks accumulation<br/>‚Ä¢ Text chunks buffering<br/>‚Ä¢ turncomplete detection<br/>‚Ä¢ State synchronization"]
    end
    
    subgraph INNOVATION["üü¢ Innovation & Excellence"]
        ChromaKey["üé® Chroma Key Processing<br/>‚Ä¢ Real-time green screen removal<br/>‚Ä¢ MP4 video layering<br/>‚Ä¢ Smooth alpha blending"]
        
        VAD["üé§ Voice Activity Detection<br/>‚Ä¢ Interrupt handling mid-response<br/>‚Ä¢ Seamless user takeover<br/>‚Ä¢ Buffer clearing strategy"]
        
        Transcripts["üìù Dual Transcripts<br/>‚Ä¢ User input captured<br/>‚Ä¢ AI response captured<br/>‚Ä¢ Supabase persistence<br/>‚Ä¢ Conversation history"]
        
        NonBlocking["‚ö° Non-Blocking Everything<br/>‚Ä¢ Memory ops don't block UI<br/>‚Ä¢ Tool calls don't block streaming<br/>‚Ä¢ Smooth 60fps rendering<br/>‚Ä¢ Zero jank user experience"]
        
        StreamSync["üåä Stream Synchronization<br/>‚Ä¢ Audio stream to speaker<br/>‚Ä¢ Video stream to avatar<br/>‚Ä¢ Text stream to captions<br/>‚Ä¢ Perfect timing synchronization"]
        
        RecoveryResilience["üõ°Ô∏è Resilience & Recovery<br/>‚Ä¢ Connection failure handling<br/>‚Ä¢ Automatic reconnection<br/>‚Ä¢ Graceful degradation<br/>‚Ä¢ Error state management"]
    end
    
    subgraph ADVANCED["üü† Advanced Features"]
        HintSystem["üí° Hint System<br/>‚Ä¢ Dynamic hint generation<br/>‚Ä¢ Tool-based execution<br/>‚Ä¢ Context-aware suggestions"]
        
        EmotionDetective["üòä Emotion Detective<br/>‚Ä¢ Sentiment analysis<br/>‚Ä¢ Emotional state tracking<br/>‚Ä¢ Response adaptation"]
        
        ResponseBuffer["üìä Response Buffer<br/>‚Ä¢ Smart buffering strategy<br/>‚Ä¢ Chunk combining logic<br/>‚Ä¢ Performance optimization"]
        
        SystemPrompt["üß† Dynamic System Prompt<br/>‚Ä¢ Memory integration<br/>‚Ä¢ Context personalization<br/>‚Ä¢ Adaptive behavior"]
    end
    
    COMPLEXITY -->|Enables| INNOVATION
    INNOVATION -->|Powers| ADVANCED
    
    style RealTime fill:#ff6b6b,stroke:#c92a2a,color:#fff
    style StateMachine fill:#ff6b6b,stroke:#c92a2a,color:#fff
    style EventDriven fill:#ff6b6b,stroke:#c92a2a,color:#fff
    style MemoryMagic fill:#ff6b6b,stroke:#c92a2a,color:#fff
    style ToolCalling fill:#ff6b6b,stroke:#c92a2a,color:#fff
    style BufferSync fill:#ff6b6b,stroke:#c92a2a,color:#fff
    
    style ChromaKey fill:#51cf66,stroke:#2f9e44,color:#fff
    style VAD fill:#51cf66,stroke:#2f9e44,color:#fff
    style Transcripts fill:#51cf66,stroke:#2f9e44,color:#fff
    style NonBlocking fill:#51cf66,stroke:#2f9e44,color:#fff
    style StreamSync fill:#51cf66,stroke:#2f9e44,color:#fff
    style RecoveryResilience fill:#51cf66,stroke:#2f9e44,color:#fff
    
    style HintSystem fill:#ffa94d,stroke:#e67700,color:#fff
    style EmotionDetective fill:#ffa94d,stroke:#e67700,color:#fff
    style ResponseBuffer fill:#ffa94d,stroke:#e67700,color:#fff
    style SystemPrompt fill:#ffa94d,stroke:#e67700,color:#fff
            </div>
            <div class="description">
                <strong>‚ö° PICO COMPLEXITY - Where the Magic Happens:</strong>
                <br><br><strong>üî¥ Core Complexity (Foundation):</strong>
                <br>‚Ä¢ <strong>Real-Time Streaming:</strong> Handles continuous bidirectional audio with sub-200ms latency
                <br>‚Ä¢ <strong>Smart State Machine:</strong> Seamlessly transitions between IDLE, BUFFERING, and TALKING states
                <br>‚Ä¢ <strong>Async Event Architecture:</strong> Non-blocking event handlers for setup, media, content, and tool calls
                <br>‚Ä¢ <strong>Memory Magic:</strong> NON_BLOCKING async memory operations that don't interrupt conversation flow
                <br>‚Ä¢ <strong>Tool Calling:</strong> Sophisticated Gemini tool execution with streaming continuation
                <br>‚Ä¢ <strong>Chunk Synchronization:</strong> Complex buffering logic ensuring audio and text stay in sync
                <br><br><strong>üü¢ Innovation & Excellence (Competitive Advantage):</strong>
                <br>‚Ä¢ <strong>Chroma Key Processing:</strong> Real-time green screen removal with smooth alpha blending
                <br>‚Ä¢ <strong>Voice Activity Detection:</strong> Intelligent interrupt handling for user takeover
                <br>‚Ä¢ <strong>Dual Transcripts:</strong> Both user and AI outputs captured and persisted
                <br>‚Ä¢ <strong>Non-Blocking Everything:</strong> Smooth 60fps rendering with zero UI jank
                <br>‚Ä¢ <strong>Stream Synchronization:</strong> Perfect timing between audio, video, and text
                <br>‚Ä¢ <strong>Resilience & Recovery:</strong> Automatic reconnection and graceful degradation
                <br><br><strong>üü† Advanced Features (Next Level):</strong>
                <br>‚Ä¢ <strong>Hint System:</strong> Dynamic hint generation powered by tool calling
                <br>‚Ä¢ <strong>Emotion Detective:</strong> Sentiment analysis and emotional adaptation
                <br>‚Ä¢ <strong>Response Buffer:</strong> Smart buffering strategy for optimal performance
                <br>‚Ä¢ <strong>Dynamic System Prompt:</strong> Personalization through memory integration
            </div>
        </div>
        
        <div id="flow" class="diagram-container">
            <h2 id="flow">üìä Complete System Data Flow</h2>
            <div class="mermaid">
graph LR
    UI["üë§ User<br/>Interface"] -->|Audio Input| Input["üé§ INPUT PHASE<br/>- Microphone<br/>- 16kHz PCM16<br/>- Transcript"]
    
    Input -->|Stream| Process["üîÑ PROCESS PHASE<br/>- Gemini analyze<br/>- Tool decision<br/>- Generate response"]
    
    Process -->|Audio + Text| Buffer["üì¶ BUFFER PHASE<br/>- Accumulate audio<br/>- Accumulate text<br/>- Detect completion"]
    
    Buffer -->|Combine| Output["üì§ OUTPUT PHASE<br/>- Play audio<br/>- Show captions<br/>- Animate avatar"]
    
    Output -->|Feedback| UI
    
    Output -->|Persist| Persist["üíæ PERSIST<br/>- localStorage<br/>- Supabase<br/>- Memories"]
            </div>
            <div class="description">
                <strong>Simplified Flow:</strong> Shows the main pipeline: Input captures audio, Process handles Gemini interaction and tools, Buffer accumulates data, Output displays everything to the user, and Persist saves conversation data for future sessions.
            </div>
        </div>
        
        <div id="journey" class="diagram-container">
            <h2 id="journey">üë• User Journey Timeline (T=0s to T=60s+)</h2>
            <div class="mermaid">
sequenceDiagram
    participant User as üë§ User
    participant Audio as üé§ Audio
    participant Gemini as ü§ñ Gemini
    participant Memory as üíæ Memory
    participant Transcript as üìù Transcript
    participant Avatar as üé≠ Avatar
    participant Speaker as üîä Speaker
    
    User->>Audio: Speaks "Hi Pico!"
    Audio->>Gemini: Send audio stream
    Gemini->>Transcript: Capture user input
    Gemini->>Gemini: Process & decide tools
    Gemini->>Memory: Call write_to_memory (async)
    Memory->>Memory: Store in localStorage
    Gemini->>Gemini: Generate response
    Gemini->>Avatar: Start buffering audio
    Avatar->>Avatar: Change to BUFFERING state
    Gemini->>Avatar: Audio & text chunks stream
    Avatar->>Avatar: Display subtitles
    Gemini->>Avatar: turncomplete event
    Avatar->>Avatar: Process complete audio
    Avatar->>Avatar: Transition to TALKING
    Avatar->>Speaker: Play audio PCM16
    Speaker->>User: Audio plays to speakers
    Avatar->>Avatar: Show talking animation
    Transcript->>Transcript: Capture AI output
    Speaker->>Speaker: Audio finished
    Avatar->>Avatar: Transition to IDLE
            </div>
            <div class="description">
                <strong>User Journey:</strong> Complete sequence showing how a single user interaction flows through the system, from speaking to getting a response with avatar animation and transcript recording.
            </div>
        </div>
        
        <div id="memory" class="diagram-container">
            <h2 id="memory">üíæ Memory System Flow</h2>
            <div class="mermaid">
graph LR
    UserInput["User: My dog is Max"]
    
    UserInput -->|Gemini Analyzes| Decision{"Should<br/>Store?"}
    
    Decision -->|YES| ToolCall["Tool Call:<br/>write_to_memory"]
    
    ToolCall -->|Function Args| Execute["Execute:<br/>key: pet_name<br/>value: Max"]
    
    Execute -->|Async| localStorage["localStorage:<br/>expresbuddy_memory_pet_name"]
    
    localStorage -->|Stored| Ready["‚úì Available in<br/>Future Sessions"]
    
    Ready -->|Next Session| Retrieve["get_memories_by_keys<br/>(['pet_name'])"]
    
    Retrieve -->|Returns| MemoryData["{ pet_name: 'Max' }"]
    
    MemoryData -->|Into System Prompt| Gemini["Gemini naturally<br/>references"]
    
    Gemini -->|Natural| Response["'How is Max?'<br/>No announcement"]
            </div>
            <div class="description">
                <strong>Memory System:</strong> Shows how memories are stored, retrieved, and integrated. The key feature is NON_BLOCKING async behavior and natural integration without announcements like "I remember..."
            </div>
        </div>
        
        <div id="avatar" class="diagram-container">
            <h2 id="avatar">üé≠ Avatar State Machine</h2>
            <div class="mermaid">
stateDiagram-v2
    [*] --> IDLE
    
    IDLE -->|AI starts| BUFFERING: onAITurnStart()
    BUFFERING -->|Audio ready| PLAYING: Audio prep
    PLAYING -->|Audio starts| TALKING: Video transition
    TALKING -->|Audio streaming| TALKING: Continuous
    TALKING -->|Audio finished| IDLE: onAITurnComplete()
    
    IDLE -->|User speaks| IDLE: Listen
            </div>
            <div class="description">
                <strong>Avatar States:</strong> Shows the avatar animation state transitions: IDLE (listening) ‚Üí BUFFERING (accumulating audio) ‚Üí PLAYING/TALKING (streaming audio and talking video) ‚Üí IDLE (ready for next input).
            </div>
        </div>
        
        <div id="tools" class="diagram-container">
            <h2 id="tools">üîß Tool Calling Lifecycle</h2>
            <div class="mermaid">
graph TD
    Define["1Ô∏è‚É£ DEFINE TOOLS<br/>(Tool Declarations)"]
    
    Define -->|Config| Config["Send to Gemini<br/>setConfig(tools)"]
    Config -->|Available| Waiting["‚è≥ Waiting"]
    Waiting -->|User speaks| Process["üîÑ Process"]
    Process -->|Decision| Decision{"Use<br/>Tools?"}
    
    Decision -->|YES| PrepTool["Prepare Tool Call"]
    Decision -->|NO| DirectResp["Direct Response"]
    
    PrepTool -->|functionCalls| Event["'toolcall' event"]
    Event -->|Handler| Parse["Parse & Extract"]
    Parse -->|Execute| Execute["Execute Tool<br/>(memory functions)"]
    Execute -->|Build| BuildResp["Build Response"]
    BuildResp -->|Send| Send["Send to Gemini"]
    Send -->|Result| Gemini["Gemini Uses Result"]
    Gemini -->|Continue| DirectResp
    
    DirectResp -->|Generate| Response["Response"]
    Response -->|Stream| Output["Output"]
            </div>
            <div class="description">
                <strong>Tool Calling:</strong> Complete lifecycle from defining tools through handling Gemini's tool calls asynchronously. Memory tools (write_to_memory, get_memories_by_keys) run non-blocking without interrupting conversation flow.
            </div>
        </div>
        
        <div id="audio" class="diagram-container">
            <h2 id="audio">üîä Audio Processing Pipeline</h2>
            <div class="mermaid">
graph TB
    MicInput["üé§ Microphone<br/>16kHz PCM16"]
    
    MicInput -->|Send| AudioStreamer["üì§ AudioStreamer"]
    MicInput -->|Capture| TransService["üìù Transcript<br/>Service"]
    
    AudioStreamer -->|Upload| GeminiAPI["ü§ñ Gemini<br/>Live API"]
    
    GeminiAPI -->|'setup'| Setup["üìä Audio Setup"]
    GeminiAPI -->|'media'| MediaEvents["üì¶ Media Events"]
    GeminiAPI -->|'content'| TextEvents["üìù Text Events"]
    
    MediaEvents -->|Buffer| AudioBuf["üîÅ Audio Buffer"]
    TextEvents -->|Accumulate| TextBuf["üì¶ Text Buffer"]
    
    TextBuf -->|Chunks| Display["üé¨ Captions"]
    
    AudioBuf -->|Check| Interrupt{"User<br/>Speaking?"}
    
    Interrupt -->|YES| Stop["üõë Interrupt"]
    Interrupt -->|NO| Normal["Continue"]
    
    Stop -->|Clear| Reset["Reset"]
    
    Normal -->|'turncomplete'| Complete["‚úÖ Complete"]
    
    Complete -->|Process| Combine["Combine Chunks"]
    Combine -->|Single| Play["üîä Play Audio"]
    
    Play -->|Output| Speaker["üîä Speaker"]
    
    Speaker -->|Finish| Cleanup["üßπ Cleanup"]
    
    Cleanup -->|Save| TransService
    
    TransService -->|Supabase| DB["üíæ Database"]
            </div>
            <div class="description">
                <strong>Audio Pipeline:</strong> Complete audio flow from microphone capture through Gemini processing, buffering, playback, and transcript saving. Includes user interruption handling via VAD (Voice Activity Detection).
            </div>
        </div>
        
        <div style="text-align: center; margin-top: 40px;">
            <p style="color: white; font-size: 1.2em; margin-bottom: 20px;">
                üí° Tip: Right-click on any diagram to save as image (SVG format)
            </p>
        </div>
    </div>
    
    <footer>
        <p>ExpressBuddy Architecture Documentation - Generated October 2024</p>
        <p>Interactive Mermaid Diagrams - Right-click to save as SVG</p>
        <p>View ARCHITECTURE_DIAGRAM.md for complete detailed documentation</p>
    </footer>
    
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
        mermaid.contentLoaded();
    </script>
</body>
</html>
